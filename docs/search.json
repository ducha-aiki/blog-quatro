[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dmytro Mishkin’s blog."
  },
  {
    "objectID": "posts/2021-02-18-how-i-read-arxiv.html",
    "href": "posts/2021-02-18-how-i-read-arxiv.html",
    "title": "How I cope with the flood of arXiv papers",
    "section": "",
    "text": "OK, that is a joke – I believe that I am dealing with the tons of papers rather fine. Here is how."
  },
  {
    "objectID": "posts/2021-02-18-how-i-read-arxiv.html#coarse-to-fine-scheme",
    "href": "posts/2021-02-18-how-i-read-arxiv.html#coarse-to-fine-scheme",
    "title": "How I cope with the flood of arXiv papers",
    "section": "Coarse-to-fine scheme",
    "text": "Coarse-to-fine scheme\nI check 100 paper titles + abstracts, I skim through maybe 10, I read carefully one or two papers. Why? The most of papers are not relevant to me as a computer vision researcher. Some of the papers are bad. From those, which are good, the most important thing is their main message, not some details. And only little number of papers are worth reading – for me. For you that would be different 1 or 2 papers out of 100, but likely not more."
  },
  {
    "objectID": "posts/2025-09-17-chatGPT-as-a-student.html",
    "href": "posts/2025-09-17-chatGPT-as-a-student.html",
    "title": "How ChatGPT fare in computer vision course homeworks at CTU in Prague.",
    "section": "",
    "text": "In the era of SWE-bench and various arenas for LLMs, the question “can LLMs code?” is obsolete. Of course, they can and I personally use ChatGPT and Sonnet4 daily. They are good.\nNow, the real question is – if the LLMs are so good, why students are struggling with coding assignments for computer vision course every year? Does Chat have any problem with coding the gaussian blur? Are students very honest and not using it at all? Are they using LLMs, but something is wrong?\nThose are the questions, which I have tried to answer last semester.\n\n\nI do the lectures and labs on the image matching part of the computer vision. During the series of 5 assignments, students have to implement:\n\nGaussian blurring and patch extraction\n(Multiscale) Harris corner detector\nSIFT descriptor and patch dominant orientation estimation\nSNN matching and homography RANSAC\nAssemble altogether into image matching pipeline.\n\nStudents have got the lectures with a theory, course wiki with task descriptions and assignment templates with API of the functions they have to implement. Most of the assignments are evaluated automatically by unit-tests and benchmarks on university server.\nIn the end, result should look like this (the widgets are provided with templates). \n\n\n\nObviously, there are many possible ways of doing it. I have selected the following: I copy-paste 3 verbatims in a single message. The structure is :\n\nPlease, implement {ASSIGNMENT-DESCRIPTION}\n{ALL-ASSIGNMENT-RELATED-PAGE}\nCode template: {TEMPLATE.PY}\n\nThis would be (almost) fair to an LLM, as it would have the same information, as the student, except the images. It also would imitate a prompt from a reasonable, but lazy student.\nAn real (shortened) example would be:\n\n\nPlease, implement imagefiltering.py - file with the following methods implemented:\ngaussian1d, gaussian_deriv1d - functions for computing Gaussian function and its first derivative.\n\n\n\n\nimage-4.png\n\n\nimport numpy as np\nimport math\nimport torch\nimport torch.nn.functional as F\nimport typing\n\n\ndef get_gausskernel_size(sigma, force_odd = True):\n    ksize = 2 * math.ceil(sigma * 3.0) + 1\n    if ksize % 2  == 0 and force_odd:\n        ksize +=1\n    return int(ksize)\n\n\ndef gaussian1d(x: torch.Tensor, sigma: float) -&gt; torch.Tensor: \n    '''Function that computes values of a (1D) Gaussian with zero mean and variance sigma^2'''\n    out =  torch.zeros(x.shape)\n    return out\n\n\ndef gaussian_deriv1d(x: torch.Tensor, sigma: float) -&gt; torch.Tensor:  \n    '''Function that computes values of a (1D) Gaussian derivative'''\n    out =  torch.zeros(x.shape)\n    return out\n\n\n\n\nDuring the course of the semester, I have prompted the 4o, o3mini, o3 mini-hight, and o1 OpenAI models the same way, saved the .py file and uploaded it to the automatic evaluation system. When the current assignment required the functions from the previous weeks, I imported the ground truth solution – assuming that the students could perfect them via multiple attempts (we allow up to ~50 attempts to reupload homework).\nHere are the results (I added GPT5 later):\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel/task\n4o\no3-mini\no3-mini-high\no1\nGPT5-Instant\nGPT5-Thinking\nMaximum\n\n\n\n\nImage filtering\n3\n5\n2\n6\n6\n7\n7\n\n\nHarris detector\n4\n5\n5\n6\n6\n6\n7\n\n\nSIFT descriptor\n2\n4\n0\n3\n4\n4\n4\n\n\nMatching and RANSAC\n3\n7\n7\n6\n8\n3\n8\n\n\nTotal points\n12\n21\n14\n21\n24\n20\n26\n\n\nPercentage [%]\n46\n81\n54\n81\n92\n77\n100\n\n\n\nOverall, LLMs did better, than an average student on their first attempt. If prompted with scores and errors, they were pretty good at fixing their mistakes. This makes me wonder, why people, who obviously used LLM for their assignment still struggle to get high scores. And those, who get the highest scores are mostly NOT using LLMs, given the style and the iterations required to get to the answer.\nFunny enough, the tasks, which students usually struggle with, gave LLMs hard times as well.\nFor example, almost everyone missed the following sentence about strict maximum in the nms2d function description.\n (i.e. take to consideration all 8 points in the 3×3 neigborhood and output non-zero only if the center is strictly larger than the neighborhood)\nTwo of the tasks are actually benchmark based – patch orientation datection, and SIFT patch descriptor. Here are the results:\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmark/model\n4o\no3-mini\no3-mini-high\no1\nGPT5-Instant\nGPT5-Thinking\nReference Implementation\n\n\n\n\nAng. Error [deg]\nfail\n12.30\ntimeout\n22.10\n14.1\n4.20\n1.1\n\n\nSIFT mAP [%]\nfail\n64.8\ntimeout\nfail\n68.4\n73\n71.7\n\n\n\nOriginally I wanted to evaluate all CV tasks from our course – including retrieval, CNN training, tracking. However, dirung the semester, OpenAI has been updating and changing their models a couple of times, and I lost the motivation to redo the work.\n\n\n\nI believe, modern LLMs – even if in “single attempt” mode could easily ace university coding assignemnt. Even more so in “agentic” mode. Relying on ban for LLM usage is futile. Instead we should ask questions like - how do we teach people to do software engineering, and especially deep understanding of the algorithms in the ChatGPT era. The emphasis here on the understanding and the final result - good engineer, and not on the stupid things like “how can we prevent students from using LLMs”. We cannot.\nWhat is troubling to me, is when student could not get good results even with ChatGPT help."
  },
  {
    "objectID": "posts/2025-09-17-chatGPT-as-a-student.html#evaluation",
    "href": "posts/2025-09-17-chatGPT-as-a-student.html#evaluation",
    "title": "How ChatGPT fare in computer vision course homeworks at CTU in Prague.",
    "section": "",
    "text": "During the course of the semester, I have prompted the 4o, o3mini, o3 mini-hight, and o1 OpenAI models the same way, saved the .py file and uploaded it to the automatic evaluation system. When the current assignment required the functions from the previous weeks, I imported the ground truth solution – assuming that the students could perfect them via multiple attempts (we allow up to ~50 attempts to reupload homework).\nHere are the results (I added GPT5 later):\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel/task\n4o\no3-mini\no3-mini-high\no1\nGPT5-Instant\nGPT5-Thinking\nMaximum\n\n\n\n\nImage filtering\n3\n5\n2\n6\n6\n7\n7\n\n\nHarris detector\n4\n5\n5\n6\n6\n6\n7\n\n\nSIFT descriptor\n2\n4\n0\n3\n4\n4\n4\n\n\nMatching and RANSAC\n3\n7\n7\n6\n8\n3\n8\n\n\nTotal points\n12\n21\n14\n21\n24\n20\n26\n\n\nPercentage [%]\n46\n81\n54\n81\n92\n77\n100\n\n\n\nOverall, LLMs did better, than an average student on their first attempt. If prompted with scores and errors, they were pretty good at fixing their mistakes. This makes me wonder, why people, who obviously used LLM for their assignment still struggle to get high scores. And those, who get the highest scores are mostly NOT using LLMs, given the style and the iterations required to get to the answer.\nFunny enough, the tasks, which students usually struggle with, gave LLMs hard times as well.\nFor example, almost everyone missed the following sentence about strict maximum in the nms2d function description.\n (i.e. take to consideration all 8 points in the 3×3 neigborhood and output non-zero only if the center is strictly larger than the neighborhood)\nTwo of the tasks are actually benchmark based – patch orientation datection, and SIFT patch descriptor. Here are the results:\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmark/model\n4o\no3-mini\no3-mini-high\no1\nGPT5-Instant\nGPT5-Thinking\nReference Implementation\n\n\n\n\nAng. Error [deg]\nfail\n12.30\ntimeout\n22.10\n14.1\n4.20\n1.1\n\n\nSIFT mAP [%]\nfail\n64.8\ntimeout\nfail\n68.4\n73\n71.7\n\n\n\nOriginally I wanted to evaluate all CV tasks from our course – including retrieval, CNN training, tracking. However, dirung the semester, OpenAI has been updating and changing their models a couple of times, and I lost the motivation to redo the work."
  },
  {
    "objectID": "posts/2025-09-17-chatGPT-as-a-student.html#conclusion",
    "href": "posts/2025-09-17-chatGPT-as-a-student.html#conclusion",
    "title": "How ChatGPT fare in computer vision course homeworks at CTU in Prague.",
    "section": "",
    "text": "I believe, modern LLMs – even if in “single attempt” mode could easily ace university coding assignemnt. Even more so in “agentic” mode. Relying on ban for LLM usage is futile. Instead we should ask questions like - how do we teach people to do software engineering, and especially deep understanding of the algorithms in the ChatGPT era. The emphasis here on the understanding and the final result - good engineer, and not on the stupid things like “how can we prevent students from using LLMs”. We cannot.\nWhat is troubling to me, is when student could not get good results even with ChatGPT help."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dmytro's Blog",
    "section": "",
    "text": "How ChatGPT fare in computer vision course homeworks at CTU in Prague.\n\n\n\n\n\n\ncomputer vision\n\n\nresearch\n\n\nteaching\n\n\nAI\n\n\n\nBetter than average human?\n\n\n\n\n\nSep 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHow I cope with the flood of arXiv papers\n\n\n\n\n\n\narXiv\n\n\nresearch\n\n\npreprints\n\n\n\nhope, that it could help you as well\n\n\n\n\n\nFeb 18, 2021\n\n\n\n\n\n\nNo matching items"
  }
]